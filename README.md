# CIT-EmotionNet
 The model integrates Convolutional Neural Network (CNN) and Transformer within a single framework in a parallel manner for EEG-based emotion recognition problem. 

 We propose a Convolution Interactive Transformer module, which facilitates the interaction and fusion of local and global features extracted by CNN and Transformer respectively, thereby improving the average accuracy of emotion recognition. The proposed CIT-EmotionNet outperforms state-of-the-art methods, achieving an average recognition accuracy of 98.57% and 92.09% on two publicly available datasets, SEED and SEED-IV, respectively.

Links to datasets:
- SEED: https://bcmi.sjtu.edu.cn/home/seed/downloads.html#seed-access-anchor
- SEED IV: https://bcmi.sjtu.edu.cn/home/seed/downloads.html#seed-iv-access-anchor